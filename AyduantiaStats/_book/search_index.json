[
["index.html", "Practicos de Bioestadística 2 Requerimientos 0.1 Antes de comenzar 0.2 Descripción del práctico 0.3 Objetivos del práctico 0.4 Contenidos 0.5 Metodología 0.6 Evaluación 0.7 Presentación de introducción", " Practicos de Bioestadística 2 Derek Corcoran 2019-04-17 Requerimientos Para comenzar el trabajo se necesita la última versión de R y RStudio (R Core Team 2018).También se requiere de los paquetes pacman, rmarkdown, tidyverse y tinytex. Si no se ha usado R o RStudio anteriormente, el siguiente video muestra cómo instalar ambos programas y los paquetes necesarios para este curso en el siguiente link. El código para la instalación de esos paquetes es el siguiente: install.packages(&quot;pacman&quot;, &quot;rmarkdown&quot;, &quot;tidyverse&quot;, &quot;tinytex&quot;) En caso de necesitar ayuda para la instalación, contactarse con el instructor del curso. 0.1 Antes de comenzar Si nunca se ha trabajado con R antes de este curso, una buena herramienta es provista por el paquete Swirl (Kross et al. 2017). Si deseas estar más preparado para el curso, realiza los primeros 7 módulos del programa R Programming: The basics of programming in R que incluye: Basic Building Blocks Workspace and Files Sequences of Numbers Vectors Missing Values Subsetting Vectors Matrices and Data Frames El siguiente link muestra un video explicativo de cómo usar el paquete swirl Video 0.2 Descripción del práctico Los prácticos de este curso se enfocan en aprender a realizar de manera práctica los conceptos enseñados en el cuso, pero además, usando herramientas interactivas y/o programáticas, el profundizar el entendimiento de ciertos conceptos teóricos y filosóficos del curso. 0.3 Objetivos del práctico Aprender el uso de R como ambiente estadístico de limpieza, exploración, visualización de datos. Conocer y aplicar de manera aplicada los conceptos enseñados en el curso de Bioestadística 2. Aprender buenas prácticas de recolección y estandarización de bases de datos, con la finalidad de optimizar el análisis de datos y la revisión de éstas por pares. Realizar análisis críticos de la naturaleza de los datos al realizar análisis exploratorios, que permitirán determinar la mejor forma de comprobar hipótesis asociadas a estas bases de datos. 0.4 Contenidos Capítulo 1 Análisis exploratorio y el primer ANOVA: En este capítulo se aprenderá a cómo explorar, resumir y visualizar una base de datos utilizando el paquete tidyverse (Wickham 2017), además se realizarán un análisis básico de ANOVA Capítulo 2 Supuestos de ANOVA y mínimos cuadrados Capítulo 3 Análisis de poder y primera tarea Capítulo 7 Referencias Capítulo 4 T de student Capítulo 5 Tests posthoc Capítulo 6 Como formular tu ANOVA 0.5 Metodología Clases prácticas donde cada estudiante trabajará con datos entregados para desarrollar análisis de datos. Además, se deberán generar informes, en base al trabajo con sus datos. 0.6 Evaluación El trabajo práctico de este ramo es un 20% de la nota final del curso, y es obligatorio ir a todos los trabajos prácticos para pasar el ramo. Durante los primeros 15 minutos se tomará un control. Pasado ese período, no se acepta la entrega de controles, recibiendo calificación 1. La ausencia a los trabajos prácticos puede ser causal de reprobación del curso. Ademas de los controles habrán trabajos de investigación. La nota final de los practicos se evaluará de la siguiente forma: Tests de entrada: 60% Trabajos: 40% 0.7 Presentación de introducción Para la introducción de los prácticos seguiremos un a presentación que se encuentra en este link Si no has conseguido instalar R, puedes seguir el práctico usando la siguiente guía interactiva Puedes ver la clase de nuevo en el siguiente video o clickeando en este link Referencias "],
["Explorando.html", "Práctico 1 Exploración de datos y tu primer ANOVA 1.1 Paquetes necesarios para este práctico 1.2 Actividad 1 Educación en Chile 1.3 Actividad 2 Captación de CO2 en plantas 1.4 Actividad 3 Mi primer ANOVA", " Práctico 1 Exploración de datos y tu primer ANOVA 1.1 Paquetes necesarios para este práctico Para este capitulo necesitas tener instalado el paquete tidyverse. Esta clase del curso puede también ser seguida en este link. El video de la clase se encuentra disponible en este link. 1.2 Actividad 1 Educación en Chile En esta actividad exploraremos los resultados de la PSU en Chile para el año 2017. Pueden encontrar la base de datos original en Data Chile. Trataremos de determinar, usando el puntaje de la PSU como medida, si existen brechas en la educación chilena por tipo de institución. Para ello, primero trabajaremos realizando análisis exploratorios en base a gráficos y tablas resumen usando funciones del paquete tidyverse (Wickham 2017) en R. La base de datos EducacionChile.csv se encuentra disponible en webcursos o en https://es.datachile.io/geo/chile#education. 1.2.1 Tablas resumen de los datos: Lo primero que deben hacer es generar una tabla resumen usando el tidyverse usando las funciones group_by para agrupar por variables y summarize para resumir los datos, dentro de summarize podemos usar variables como: mean() promedio sd() desviación estándar n() número de muestras a modo de ejemplo vemos la tabla 1.1 mostrando la media y número de muestras con la base de datos iris: data(&quot;iris&quot;) Table &lt;- group_by(iris, Species) %&gt;% summarize(Promedio = mean(Petal.Length), N = n()) knitr::kable(Table) Tabla 1.1: Resumen con la media y número de muestras del largo de pétalo de las flores de tres especies del género Iris Species Promedio N setosa 1.462 50 versicolor 4.260 50 virginica 5.552 50 Basado en el resumen ¿Qué podemos decir de estos datos de educación en Chile? 1.2.2 Visualización de datos con ggplot2 (tidyverse) El paquete ggplot2 (Wickham 2016) es una poderosa herramienta para graficar datos. Si desean ahondar en el uso de este paquete, pueden ver el siguiente link http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/. En este caso, aprenderemos a graficar boxplots y jitterplots, dos opciones para visualizar una variable categórica versus una cuantitativa. 1.2.2.1 Uso del ggplot2 Su función principal es ggplot, luego de cada función usaremos el símbolo + como usábamos el pipeline (%&gt;%). Primero usamos la función ggplot para determinar la base de datos y variables, acá las variables siempre van dentro de la función aes ggplot(MiBaseDeDatos, aes(x = VariableX, y = VariableY)) Luego agregamos el tipo de gráfico que queremos para nuestra figura usando el + como pipeline ggplot(MiBaseDeDatos, aes(x = VariableX, y = VariableY)) + geom_boxplot() 1.2.2.2 Ejemplo usando la base de datos iris 1.2.2.2.1 Boxplot El siguiente código muestra como graficar un boxplot para la base de datos iris, la cual esta en R. En este caso graficaremos el largo del pétalo para cada especie (Figura 1.1). data(&quot;iris&quot;) ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot() Figura 1.1: Box plot del largo de petalo de tres especies del género Iris En los Box Plots tenemos 4 visualizaciones: Mediana (linea gruesa) Caja (Cuantiles 25% y 75%) Bigotes (intervalo de confianza del 95%) Puntos Outlayers Realice un boxplot de los datos de la educación de Chile, ¿Qué nos dice esto de los datos? 1.2.2.2.2 Jitter plot El jitter plot suma un punto por cada observación, lo cual nos permite entender un poco más la naturaleza de los datos. En general se le agrega a un box plot para tener mayor claridad en los datos (Figura 1.2). data(&quot;iris&quot;) ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot() + geom_jitter(aes(color = Species)) Figura 1.2: Box plot y jitter plot juntos para el largo de petalo de tres especies del género Iris 1.3 Actividad 2 Captación de CO2 en plantas Utilizaremos base de datos \\(CO_2\\) (Potvin, Lechowicz, and Tardif 1990) enviada al curso. Esta base de datos, también presente en R, tiene las siguientes variables Plant: Identidad de cada planta Type: Variedad de la planta (subespecie Quebec o Mississippi) Treatment: Tratamiento de la planta, algunas fueron enfriadas la noche anterior (Chilled) conc: Concentración ambiental de \\(CO_2\\) Uptake: Captación de \\(CO_2\\) para cada planta en cada día ¿Hay diferencias entre la captación de \\(CO_2\\) en plantas tratadas y no tratadas? Genere tablas resumenes que le permitan explorar esta pregunta ¿Existen variables que puedan confundir el resultado? ¿como trataría los datos para lidiar con esto? Genere gráficos exploratorios para contestar esta pregunta 1.4 Actividad 3 Mi primer ANOVA 1.4.1 antes de empezar a entender el ANOVA El ANOVA compara medias entre grupos, lo principal es la comparación entre los cuadrados de los residuales intergrupos, y los residuales intragrupos, los primeros son los cuadrados de la diferencia entre las medias de todas las observaciones (\\(\\tilde{x}_t\\)) y las medias de cada grupo \\(\\tilde{x}_g\\) al cuadrado multiplicado por el número de observaciones totales (ver ecuación (1.1)), cambia las medias del simlador de anova a continuacion y selecciona los errores intergrupos y ve como cambian. \\[\\begin{equation} \\textrm{Errores_inter_factor} = n \\times \\sum{(\\tilde{x}_t - \\tilde{x}_g)^2} \\tag{1.1} \\end{equation}\\] los residuales intra grupos son la diferencia entre cada observación \\(x_{i,g}\\) del grupo \\(g\\) y las medias del grupo respectivo (ver ecuación (1.2)), cambia las medias del simlador de anova a continuacion y selecciona los errores intragrupos y ve como cambian \\[\\begin{equation} \\textrm{Errores_intra_factor} = \\sum{(\\tilde{x}_g - x_{i,g})^2} \\tag{1.2} \\end{equation}\\] 1.4.1.1 Simulador de ANOVA 1.4.2 Como hacer un ANOVA en R En R todos los modelos tienen la siguiente estructura Funcion(y ~ x1 + x2 + … + xn, data = MisDatos), donde la Funcion dice el modelo que queremos realizar (por ejemplo ANOVA, regresión lineal, modelos mixtos, etc.), y es la variable que queremos explicar, x1 a xn son las variables explicativas, ~ es un símbolo que debe ser leído como explicado por y finalmente data es la base de datos que queremos utilizar, en un ANOVA (análisis de varianza), la función en cuestión es aov. En el siguiente código vemos si el largo del pétalo de las flores del género Iris, pueden ser explicados por la especie a la que estas plantas pertenecen, por lo que generamos un modelo llamado Primer.Anova con la función aov. Primer.Anova &lt;- aov(Petal.Length ~ Species, data = iris) Para acceder a la tabla de resultados utilizamos la función summary ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 2 437.1 218.55 1180 &lt;2e-16 *** ## Residuals 147 27.2 0.19 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Si establecemos el valor de alfa en 0.05 y al ver en la tabla que el valor de p es menor a alfa, rechazamos la hipótesis nula de que las medias son iguales, y decidimos que la media del largo de pétalo es distinta entre las especies. 1.4.3 Ejercicio Determine si para la base de datos CO2 la captación de \\(CO_2\\) es distinto entre plantas con tratamiento de enfriamiento y sin enfriamiento. Referencias "],
["Supuestos.html", "Práctico 2 Supuestos de ANOVA y mínimos cuadrados 2.1 Paquetes necesarios para este práctico 2.2 Objetivos de este práctico 2.3 Actividad 1 Sueño en mamíferos 2.4 Actividad 2 Suma de cuadrados 2.5 Referencias", " Práctico 2 Supuestos de ANOVA y mínimos cuadrados 2.1 Paquetes necesarios para este práctico Para este capitulo necesitas tener instalado el paquete tidyverse, también ayuda tener el paquete broom. Esta clase del curso puede también ser seguida en este link. El video de la clase se encuentra disponible en este link. 2.2 Objetivos de este práctico Entender los supuestos de un ANOVA de una vía (independencia, aleatoriedad, homocedasticidad y normalidad) Entender el concepto de mínimos cuadrados Saber cuando realizar un ANOVA e interpretar sus resultados 2.3 Actividad 1 Sueño en mamíferos En esta actividad intentaremos ver si hay diferencias en horas de sueño en mamíferos por Orden o dieta. Los datos fueron extraídos del trabajo de Savage and West (2007) y están incorporados en la base de datos de ggplot2 con el nombre de msleep, pero estarán en webcursos en formato csv de todas formas. Para la guía los ejemplos se generarán en base a la base de datos InsectSprays que está en R y que fue extraída de Beall (1942), en la cual se testean la efectividad de insecticidas en Spray en la abundancia de insectos en plantaciones. Y en la base de datos iris que ya fue entregada, en la que se miden distintas características florales de especies del genero Iris (Anderson 1935). 2.3.1 Homogeneidad de varianza 2.3.1.1 Inspección visual Lo primero que intentaremos explorar de forma visual y a partir de tests si es que hay homogeneidad de varianza, para esto usaremos boxplots, y jitter plots (Figura 2.1), lo cual ya hemos hecho anteriormente: ggplot(InsectSprays, aes(x = spray, y = count)) + geom_boxplot() + geom_jitter(aes(color = spray)) Figura 2.1: Cuenta de insectos según tipo de insecticida Para explorar visualmente si existe homogeneidad de varianza, se compraran las cajas y bigotes de los boxplots y se espera que tengan (Mas o menos distintos tamaños). 2.3.1.2 Test de Bartlett Para realizar un test de homogeneidad de varianza se realiza el test de bartlett (Bartlett 1937), en este se usa nuestra conocida formula y ~ x, esto es, y explicado por x junto a la función bartlett.test. Para nuestro caso usaríamos: ## ## Bartlett test of homogeneity of variances ## ## data: count by spray ## Bartlett&#39;s K-squared = 25.96, df = 5, p-value = 9.085e-05 Como en este caso, no el valor de p es menor a 0.05, decimos que no hay homogeneidad de varianza, por lo que no podemos hacer el test. 2.3.2 Normalidad de los residuales En el caso de la base de datos iris, demostraremos inmediatamente que si hay homogeneidad de varianza en el ancho del sépalo (Figura 2.2): Figura 2.2: Ancho de sépalo según especie del género Iris ## ## Bartlett test of homogeneity of variances ## ## data: Sepal.Width by Species ## Bartlett&#39;s K-squared = 2.0911, df = 2, p-value = 0.3515 Debido a ello, podemos testar si los residuales tienen una distribución normalidad de los residuales, para esto lo primero que debemos hacer es un ANOVA, como fue explicado en el práctico anterior y guardar este objeto con un nombre: 2.3.2.1 Extracción de los residuales del modelo Para extraer los residuales, podemos hacerlo de dos formas, si solo queremos un vector de sus valores, podemos extraerlo desde el modelo mismo utilizando $residuals. Si queremos guardarlo en un dataframe mas completo podemos utilizar la función augment del paquete broom. La segunda opción nos entregará más información que podremos utilizar más tarde, pero ambas sirven para testear normalidad, la siguiente tabla muestra las primeras 6 observaciones generadas por la función augment, donde resid, son los residuales (Ver tabla 2.1. Tabla 2.1: primeras 6 observaciones del dataframe resultante de augment Sepal.Width Species .fitted .se.fit .resid .hat .sigma .cooksd .std.resid 3.5 setosa 3.428 0.048 0.072 0.02 0.341 0.000 0.214 3.0 setosa 3.428 0.048 -0.428 0.02 0.339 0.011 -1.273 3.2 setosa 3.428 0.048 -0.228 0.02 0.340 0.003 -0.678 3.1 setosa 3.428 0.048 -0.328 0.02 0.340 0.006 -0.975 3.6 setosa 3.428 0.048 0.172 0.02 0.341 0.002 0.511 3.9 setosa 3.428 0.048 0.472 0.02 0.339 0.013 1.404 2.3.2.2 Inspección visual de los residuales Existen dos formas de visualizar los residuales para determinar si la distribución de estos es o no es normal, histogramas y el qqplot. 2.3.2.2.1 Histograma Los histogramas nos darán una representación visual para tratar de entender si la distribución es normal, para esto, solo necesitamos usar el comando hist, seguido del vector de los residuales, este es el comando para hacer el histograma (Figura 2.3) con cualquiera de las dos bases de datos, el resultado debiera ser el mismo: hist(Residuales) hist(Resultados$.resid) Figura 2.3: Histograma de los resiudales del modelo ANOVA 2.3.2.2.2 QQplot El qq plot es otra forma visual de establecer si los residuales son o no son normales, para esto, lo esperado es que la gráfica resultante sea una diagonal lo mas recta posible, para esto usaremos la función qqnorm, con nuestros residuales, de nuevo, podemos usar cualquiera de las dos versiones de nuestros datos: qqnorm(Residuales) qqnorm(Resultados$.resid) Figura 2.4: qqplot de los resiudales del modelo ANOVA 2.3.2.3 Test de Shapiro para determinar normalidad La forma más sencilla de determinar normalidad es usando el test de Shapiro-Wilk de normalidad (Royston 1995). Al igual que el test de Bartlett, si el valor de p es menor a 0.05, determinamos que la distribución de los datos no son normales, la función en R para este test es shapiro.test, y al igual que en los casos anteriores de hist y qqpot, solo necesitamos de usar un vector de residuales para ver el resultado del test. En nuestro caso: shapiro.test(Residuales) shapiro.test(Resultados$.resid) ## ## Shapiro-Wilk normality test ## ## data: Residuales ## W = 0.98948, p-value = 0.323 Ya que el valor de p es menor a 0.05, podemos decir que la distribución de nuestros residuales es normal, y por lo tanto el test cumple con los supuestos, y esto hace que sea valido el ANOVA, por lo que podemos ver nuestros resultados. La homogeneidad de Varianza es mas importante que la normalidad de residuales para estos casos, para ejemplos de lo que se debe hacer si se viola la normalidad ver Lix, Keselman, and Keselman (1996) 2.4 Actividad 2 Suma de cuadrados Tanto los ANOVAS como las regresiones lineales se basan en minimizar la suma de cuadrados, es la suma de los cuadrados de los errores o residuales. 2.4.1 ¿Que es el error? ¿Por qué al cuadrado?? Figura 2.5: Errores de una regresión lineal ejemplificados con la linea entre el valor predicho y el observado En la figura y en la formula vemos ejemplificado que es el error, también conocido como residual, este es simplemente el valor observado \\[Observado - Predicho\\] El objetivo de todo modelo es el de minimizar estos errores, al ajustar el mejor modelo posible. Los errores siempre se calculan al cuadrado, discutiremos por que en clase \\[\\sum_{i=1}^{n} (Observado - Predicho)^2\\] 2.5 Referencias Referencias "],
["Poder.html", "Práctico 3 Análisis de poder 3.1 Obejtivos del práctico 3.2 Matriz de confusión 3.3 Calculo de poder en R", " Práctico 3 Análisis de poder Para este capitulo necesitas tener instalado el paquete pwr2, también ayuda tener el paquete broom. Esta clase del curso puede también ser seguida en este link. El video de la clase se encuentra disponible en este link. 3.1 Obejtivos del práctico Entender cálculos de poder en base a matriz de confusión Primera tarea de práctico 3.2 Matriz de confusión La matriz de confusión es una herramienta de toma de decisiones, en el caso especial de la toma de decisiones tenemos la siguiente matriz de confusión (Tabla 3.1) Tabla 3.1: Tabla de confusión de errores Hipótesis nula cierta Hipótesis alternativa cierta Acepto hipótesis nula No hay error Error tipo 2 Acepto hipótesis alternativa Error tipo 1 No hay error Esto puede ser fácilmente ejemplificado con el problema de una alarma de humo (tabla3.2), en este caso cuando la alarma suena y no hay fuego y suena la alarma tenemos un error de tipo 1, en cambio si hay fuego y la alarma no suena tenemos un error de tipo 2 Tabla 3.2: Matriz de confusión de una alarma de incendio No hay fuego Hay fuego No suena alarma No hay error Error tipo 2 Suena alarma Error tipo 1 No hay error 3.2.1 Poder y matriz de confusión Probabilidad de que suene la alarma cuando no hay fuego \\(\\alpha\\) usualmente 5% una de cada 20 alarmas es falsa ¿Cuál es el \\(\\alpha\\) de una alarma de auto? Probabilidad de que no suene la alarma cuando hay fuego \\(\\beta\\) si es 10% uno de cada 10 fuegos no es detectado poder es \\(1-\\beta\\) confianza de que fuegos son detectados 3.3 Calculo de poder en R Para hacer cálculos de poder en ANOVAS de una y dos vías en R, utilizamos el paquete pwr2 (Lu, Liu, and Koestler 2017). En este paquete podemos utilizar la función pwr.1way para determinar el poder de un ANOVA de una vía, los argumentos de esta función son: K: El número de grupos a testear n: Número de individuos por grupo Alpha: Nivel de significancia Delta: Valor mínimo a detectar Sigma: Desviación estándar de la muestra Para cálculos precisos de n necesarios para muestras usar la siguiente app Referencias "],
["t-student.html", "Práctico 4 Prueba t de Student 4.1 Supuestos de la prueba de t y alternativas 4.2 Bibliografía", " Práctico 4 Prueba t de Student Para este capitulo necesitas tener instalado el paquete tidyverse, también ayuda tener el paquete broom. Esta clase del curso puede también ser seguida en este link. Además hay una forma interactiva de esta guía en el siguiente link. El video de la clase se encuentra disponible en este link. Puedes encontrar una versión interactiva de esta guía aquí. La prueba t de student fue desarrollada por Gosset cuando trabajaba para la cervecería Guinness (Student 1908). Esta prueba permite comparar las medias de una muestra con la media teórica de una población, o comparar dos poblaciones. Una de las características de la prueba de student, es que permite la alternativa de ver si dos medias son diferentes o, si uno busca más confianza determinar si una media es mayor, o menor que otra. Para la prueba t de Student, se determina un valor de t, usando la siguiente formula (ecuación (4.1)): \\[\\begin{equation} t = \\frac{(\\bar{x} - \\mu)/(\\frac{\\sigma}{\\sqrt{n}})}{s} \\tag{4.1} \\end{equation}\\] El estadístico \\(t\\) posee un valor de p asociado dependiendo de los grados de libertad de la prueba. 4.0.1 Pruebas de una muestra Las pruebas de una muestra nos permiten poner a prueba si la media de una población son distintas a una media teórica. Como ejemplo veremos el caso de las erupciones del géiser Old Faithful, localizado en el Parque Nacional Yellowstone. Un guarda-parque del lugar dice que este géiser erupta cada 1 hora. Por suerte R posee una base de datos de Azzalini and Bowman (1990) llamada faithfull, la cual utilizaremos para determinar si esto es cierto o no usando la función t.test. Esta base de datos tiene dos columnas eruptions, que muestra la duración en minutos de cada erupción y waiting que presenta la espera en minutos entre erupciones. Cuando usamos esta función con una muestra necesitamos llenar 2 argumentos: x: Un vector con los valores numéricos de a poner a prueba mu: La media teórica a poner a prueba alternative: Puede ser “two.sided”, “less” o “greater”, dependiendo de si uno quiere probar que la muestra posee una media distinta, menor o mayor que la media teórica. En este caso haríamos lo siguiente data(&quot;faithful&quot;) t.test(x = faithful$waiting, mu = 60, alternative = &quot;two.sided&quot;) ## ## One Sample t-test ## ## data: faithful$waiting ## t = 13.22, df = 271, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 60 ## 95 percent confidence interval: ## 69.27418 72.51994 ## sample estimates: ## mean of x ## 70.89706 En este caso el valor de p nos dice que la media es diferente a 60. 4.0.1.1 Ejercicio 1 La base de datos airquality (incorporada como ejemplo en R), muestra entre otras variables las partículas de ozono en Nueva York, cada día de Mayo a Septiembre de 1973 entre las 13:00 y las 15:00 (Chambers et al. 1983). Supongamos que ustedes están a cargo de una agencia ambiental, y están estudiando en que meses deben reducir la actividad vehicular de Nueva York. Para esto planean disminuir a la mitad los pasajes del metro de Nueva York todos los meses que en promedio tengan sobre 55 ppb. Para esto deben comprobar estadisticamente que el mes en que harán esto tiene promedios sobre 55. 4.0.2 Pruebas de dos muestras Las pruebas de dos muestras nos permiten ver si hay diferencias significativas entre las medias de dos muestras. En la base de datos mtcars, hay una columna que determina si los vehículos son de cambios manuales o automáticos. En este caso 0 significa automático y 1 significa manual. En la figura 4.1 podemos ver una inspección gráfica de las posibles diferencias. Figura 4.1: Comparación de eficiencia entre vehiculos automaticos y manuales Para hacer la comparación debemos agregar el argumento var.equal el cual en este caso asumiremos que es verdad, ya que en la próxima sección veremos los supuestos de la prueba t y las consecuencias de las violaciones de estos supuestos. En este caso podemos usar el símbolo ~ a ser leído como explicado por para la prueba t de dos muestras. t.test(mpg ~ am, data = mtcars, var.equal =TRUE) ## ## Two Sample t-test ## ## data: mpg by am ## t = -4.1061, df = 30, p-value = 0.000285 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -10.84837 -3.64151 ## sample estimates: ## mean in group 0 mean in group 1 ## 17.14737 24.39231 En este caso se determinaría que los vehículos manuales (am = 1), son más eficientes que sus contra-partes automáticas. 4.0.2.1 Ejercicio 2 Para el siguiente ejercicio usaremos la base de datos BeerDark disponible en webcursos o en el siguiente link. Esta base de datos posee 7 columnas, pero usaremos solo 4 de ellas: Estilo: Separa las cervezas entre Porters y Stouts Grado_Alcoholico: El grado alcohólico de las cervezas Amargor: Valor IBU (International Bittering Units), a mayor valor más amarga la cerveza Color: A mayor valor más oscura la cerveza. Determinar si las cervezas Porter y Stouts son distintas en grado alcohólico, amargor y/o color. 4.1 Supuestos de la prueba de t y alternativas Los supuestos de la t de student son las siguientes (Boneau 1960) Independencia de las observaciones Distribución normal de los datos en cada grupo Homogeneidad de varianza 4.1.1 Prueba de una muestra Como siempre la independencia de las muestras es algo que solo puede determinarse en base a el diseño del muestreo, y por otro lado, al haber solo una muestra, la homogeneidad de varianza no es un problema, en este caso solo podemos ver si la distribución es normal. Volviendo a nuestro ejemplo de una muestra, con la base de datos faithfull, veamos en base a un histograma (figura 4.2), qqplot (figura 4.3) y test de shapiro, si los datos son normales o no: hist(faithful$waiting, xlab = &quot;Minutos de espera entre erupciones&quot;) Figura 4.2: Histograma de los minutos de espera de el géiser Old Fiathful qqnorm(faithful$waiting) Figura 4.3: QQplot de los minutos de espera de el géiser Old Fiathful shapiro.test(faithful$waiting) ## ## Shapiro-Wilk normality test ## ## data: faithful$waiting ## W = 0.92215, p-value = 1.015e-10 Como vemos en la figura 2, los datos no se ven normales, incluso se ven bimodales, lo cual significa que tiene 2 picos, en este caso uno al rededor de los 52 minutos y otro al rededor de los 85 minutos de espera (recordemos que la función hist, automáticamente usa el algoritmo de Sturges (1926), para determinar como dividir los datos y obtener el mejor histograma). Nuestras sospechas de no normalidad son confirmadas al ver el qqplot, que no sigue para nada la diagonal, y es reafirmado por el test de shapiro, cuyo valor mucho menor a 0.05, nos dice que la distribución no es normal. Dado esto, debemos apelar a un test de distribución libre como el de Mann-Whitney, la cual se realiza con la función wilcox.test, de la misma forma que es utilizada la función t.test, por lo tanto para nuestro ejemplo usamos: data(&quot;faithful&quot;) wilcox.test(x = faithful$waiting, mu = 60, alternative = &quot;two.sided&quot;) ## ## Wilcoxon signed rank test with continuity correction ## ## data: faithful$waiting ## V = 31048, p-value &lt; 2.2e-16 ## alternative hypothesis: true location is not equal to 60 Que en este caso nos lleva a la misma conclusión que nuestro ejemplo anterior. 4.1.2 Prueba de dos muestras Para una prueba de dos muestras, podemos testear tanto la homogeneidad de varianza como la normalidad, para ver las dos cosas al mismo tiempo podemos usar un gráfico de violín (figura 4.4). En este caso, las distribuciones no se ven muy diferentes a la normalidad, pero las varianzas se ven un tanto distintas, podemos seguir explorando esto visualmente usando la función hist previamente generando dos data frames, uno para autos automático y otro para manuales. data(&quot;mtcars&quot;) mt &lt;- mtcars mt$am &lt;- ifelse(mtcars$am == 0, &quot;automatico&quot;, &quot;manual&quot;) mt &lt;- as.data.frame(mt) ggplot(mt, aes(x = am, y = mpg)) + geom_violin() Figura 4.4: Comparación de distribuciones y varianzas de los vehiculos automáticos En este caso, las distribuciones no se ven muy diferentes a la normalidad, pero las varianzas se ven un tanto distintas, podemos seguir explorando esto separando los datos en vehículos automáticos y manuales para hacer histogramas, en este caso es importante que los ejes sean iguales, para eso en el histograma usaremos los parámetros ylim y xlim. hist(manuales$mpg, xlim = c(10,35), ylim = c(0,5)) Figura 4.5: Histograma de vehiculos manuales hist(autos$mpg, xlim = c(10,35), ylim = c(0,5)) Figura 4.6: Histograma de vehiculos automáticos Como vemos, los vehículos manuales no parecen tener distribución normal como se ve en la figura 4.5, esto podemos comprobarlo con el qqlot de los mismos datos (figura 4.7) qqnorm(manuales$mpg) Figura 4.7: QQplot de eficiencia de vehiculos con cambios manuales 4.1.2.1 Ejercicio 3 Como siempre la independencia de las muestras es algo que solo puede determinarse en base a el diseño del muestreo, y por otro lado, al haber solo una muestra, la homogeneidad de varianza no es un problema, en este caso solo podemos ver si la distribución es normal. Volviendo a nuestro ejercicio de una muestra, con la base de datos airquality, evalúe basado en histograma, qqplot y test de shapiro si se debe revaluar la hipótesis para los meses de julio y agosto Para una prueba de dos muestras, podemos testear tanto la homogeneidad de varianza como la normalidad, para ver las dos cosas al mismo tiempo podemos usar un gráfico de violín geom_violin en ggplot2, lo cual puede seguir siendo explorando esto visualmente usando la función hist generando dos data frames, uno por cada clase de datos. Evalúe si es necesario revaluar la hipótesis de que el amargor es distinto entre ambos estilos de cerveza 4.2 Bibliografía Referencias "],
["posthoc.html", "Práctico 5 Comparaciones posthoc y diseños anidados 5.1 Comparaciones posthoc 5.2 Diseños anidados 5.3 Tarea 1 5.4 Referencias", " Práctico 5 Comparaciones posthoc y diseños anidados Para este capitulo necesitas tener instalado el paquete tidyverse, también ayuda tener el paquete broom. Esta clase del curso puede también ser seguida en este link El video de la clase se encuentra disponible en este link. 5.1 Comparaciones posthoc Como ya vimos en los prácticos anteriores, un ANOVA sólo puede decirnos si hay diferencias entre grupos, sin embargo no nos dira entre que grupos hay diferencias, es para esto que existen las pruebas posthoc. En el práctico de hoy veremos dos tipos de comparaciones posthoc, la prueba honesta de diferencias significativas de Tukey (función TukeyHSD en R), y los ajustes de valores de p para comparaciones multiples (función pairwise.t.test en R), de las cuales la de Bonferroni es la más habitual. 5.1.1 Prueba honesta de diferencias significativas de Tukey 5.1.1.1 Ejemplo ancho de spealo en el genero Iris Como vimos en nuestro ejemplo de la guía número 3 (Análisis exploratorio y el primer ANOVA), el ANOVA para determinar si hay diferencias en el ancho de sépalo entre las diferentes especies del genero Iris, son significativas: summary(aov(Sepal.Width ~ Species, data = iris)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 2 11.35 5.672 49.16 &lt;2e-16 *** ## Residuals 147 16.96 0.115 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Pero este análisis no nos dice en tre que especies encontramos estas diferencias, para esto, podemos realizar una prueba honesta de diferencias significativas de Tukey, para esto utilizamos la función TukeyHSD y usamos como argumento un ANOVA ya ajustado AnovaSepalo &lt;- aov(Sepal.Width ~ Species, data = iris) TukeyHSD(AnovaSepalo) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = Sepal.Width ~ Species, data = iris) ## ## $Species ## diff lwr upr p adj ## versicolor-setosa -0.658 -0.81885528 -0.4971447 0.0000000 ## virginica-setosa -0.454 -0.61485528 -0.2931447 0.0000000 ## virginica-versicolor 0.204 0.04314472 0.3648553 0.0087802 5.1.2 Ajustes de valores de p para comparaciones multiples 5.1.2.1 Ajuste de Bonferroni Cuando realizamos multiples comparaciones pareadas entre grupos, la probabilidad de encontrar diferencias significativas cuando no los hay (error tipo I), aumenta a una tasa dada por la siguiente fórmula: \\[\\alpha_{ajustado} = 1 - (1 -\\alpha)^n\\] Donde \\(\\alpha\\) es la probabilidad de cometer un error tipo I que estamos dispuestos a aceptar (tipicamente 0.05), y \\(n\\) es el numero de pruebas independientes a realizar. Con esto según el ajuste de Bonferroni, nuestro p critico para determinar diferencias significativas cambia segun la siguiente fórmula (J. W. Tukey 1977) \\[p-critico_{ajustado} = 1 - (1 -\\alpha)^{1/n}\\] El ajuste de Bonferroni, sin embargo al disminuir los errores de tipo I, aumenta los errores de tipo II (Morgan 2007). En ese sentido, la función de R pairwise.t.test, nos permite utilizar varios ajustes menos conservadores incluyendo los de Holm (1979), Hochberg (1988), Hommel (1988), Benjamini &amp; Hochberg (1995) o el de Benjamini &amp; Yekutieli (2001) 5.1.2.2 Ejemplo ancho de spealo en el genero Iris Volviendo al mismo ejemplo que usamos en la prueba de Tukey, mostraremos los valores de p determinados para comparaciones multiples de el ancho de sepalo sin ajuste y con diversos ajustes que encontramos en el la función pairwise.t.test 5.1.2.2.1 Sin ajuste pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = &quot;none&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: airquality$Ozone and airquality$Month ## ## 5 6 7 8 ## 6 0.60877 - - - ## 7 2.9e-05 0.01023 - - ## 8 1.9e-05 0.00831 0.91744 - ## 9 0.32545 0.85838 0.00070 0.00048 ## ## P value adjustment method: none 5.1.2.2.2 Ajuste de Bonferroni pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = &quot;bonf&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: airquality$Ozone and airquality$Month ## ## 5 6 7 8 ## 6 1.00000 - - - ## 7 0.00029 0.10225 - - ## 8 0.00019 0.08312 1.00000 - ## 9 1.00000 1.00000 0.00697 0.00485 ## ## P value adjustment method: bonferroni 5.1.2.2.3 Ajuste de Holm pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = &quot;holm&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: airquality$Ozone and airquality$Month ## ## 5 6 7 8 ## 6 1.00000 - - - ## 7 0.00026 0.05113 - - ## 8 0.00019 0.04987 1.00000 - ## 9 1.00000 1.00000 0.00488 0.00388 ## ## P value adjustment method: holm 5.1.2.2.4 Ajuste de Hommel pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = &quot;hommel&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: airquality$Ozone and airquality$Month ## ## 5 6 7 8 ## 6 0.91744 - - - ## 7 0.00026 0.05113 - - ## 8 0.00018 0.04156 0.91744 - ## 9 0.91744 0.91744 0.00488 0.00339 ## ## P value adjustment method: hommel 5.1.2.2.5 Diferencias Se observa como sin ajustar hay 6 pares de meses que tienen diferencias, en contraste con 4 pares de meses con el ajuste de Bonferroni, y 5 con los otros métodos de ajuste de valor de p. 5.2 Diseños anidados Los diseños anidados ocurren cuando queremos estudiar el efecto de un factor, pero dentro de las muestras existe un segundo factor que puede afectar nuestros análisis, por ejemplo si volvemos a el caso en de la base de datos CO2 5.3 Tarea 1 La municipalidad de Muy muy lejano tiene un sistema de 5 lagos muy contaminados. Se le encarga estudiar la capacidad biorremediadora de las algas unicelulares Chlorellia fecolitica (desde ahora alga A) y Rhodollia coprofaga (en adelante alga B). Para realizar el experimento y posteriormente comprar cepas para biorremediación. Con un presupuesto de 50,000 coronas, donde cada cultivo de alga cuesta 1,000 coronas. Utilizando la siguiente app realize un experimento, y luego genere un informe en formato paper donde aparezca lo siguiente: Realiza un calculo de poder en base al archivo Presamp.csv para ver cual debiera ser tu número de mustras necesaria y explicalo Establece si se cumplen los supuestos de los test a realizar y ejecuta deacurdo a tus conocimientos justificando Determinar si alguna de las algas es mejor biorremediador (incluyendo comparaciones post-hoc) Dentro de lo posible utiliza la menor cantidad posible de presupuesto, debes utilizar el presupuesto que te queda para proponer una medida de biorremediación 5.4 Referencias Referencias "],
["Formula.html", "Práctico 6 Como formular tu ANOVA 6.1 ANOVA(s) 6.2 Variables fijas vs aleatoreas 6.3 Referencias", " Práctico 6 Como formular tu ANOVA Para este capitulo necesitas tener instalado el paquete tidyverse, también ayuda tener el paquete broom. Esta clase del curso puede también ser seguida en este link 6.1 ANOVA(s) Si bien el ANOVA puede ser pensado como una extensión de una prueba de T de student, es mucho más complejo que eso, existen muchos tipos de anovas y sus combinaciones, tales como: ANOVA ANOVA factorial o en bloque ANOVA anidado o jerarquico ANOVA desbalanceado Tanta es la variedad de ANOVAS que existen muchos libros dedicados exclusivamente a la discusión de este tipo de análisis (Girden 1992) 6.1.1 ANOVA simple En la versión más senilla del ANOVA, varios grupos comparten una variable que creemos que es diferente entre grupos, como por ejemplo ancho de sepalo puede ser differente entre tres especies de Iris, para analizar esto, usaríamos el siguiente código, lo que muestra diferencias en el ancho de sépalo entre especies, lo cual se aprecia en el gráfico 1. ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 2 11.35 5.672 49.16 &lt;2e-16 *** ## Residuals 147 16.96 0.115 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Figura 6.1: Relación entre el ancho del sépalo y las especies de Iris 6.1.2 ANOVA factorial En el ANOVA factorial, más de un factor puede afectar nuestra variable respuesta. Además, estas variables pueden interactuar, haciendo que el efecto de sobre las muestras sea mas complejo que el efecto de cada variable. Un ejemplo de análisis es la economía de combustible en mtcars según si es automático o manual y el número de cilindros que tiene. En este caso modificaremos la base de datos para que el factor am en vez de numerico sea factor: ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## am 1 405.2 405.2 46.892 1.93e-07 *** ## cyl 1 449.5 449.5 52.029 7.50e-08 *** ## am:cyl 1 29.4 29.4 3.407 0.0755 . ## Residuals 28 241.9 8.6 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Aquí vemos que si hay una interacción. Las interacciones las notamos rápidamente en figuras como la que vemos en el grafico 2 imagen B, en la cual cada vez que las lineas no sean paralelas diremos que hay una interacción. Figura 6.2: Relación entre el número de cilindros, transmición automática o manual, y la economía de combustible de los vehiculos, la relacion la mostramos como un boxplot (A) y como barras de errores unidas por sus medias (B), esta última interpretación permite ver gráficamente las interacciones entre factores 6.1.3 ANOVA anidado o jerarquico En este tipo de ANOVA tenemos un factor jerarquicamente dentro de otro, por ejemplo individuos dentro de una especie, hojas dentro de un árbol o varias medidas dentro de un mismo individuo. En R dentro de la función aov, si el factor \\(B\\) esta anidado dentro de \\(A\\) tenemos A/B como una variable explicativa. Si usamos como ejemplo la de datos CO2, los individuos de cada subespecie estan anidados dentro de cada subespecie. Esto sería analizado con el siguiente codigo: ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Type 1 3366 3366 50.017 8.13e-10 *** ## Treatment 1 988 988 14.685 0.000269 *** ## Type:Treatment 1 226 226 3.355 0.071152 . ## Type:Plant 8 283 35 0.525 0.833637 ## Residuals 72 4845 67 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.2 Variables fijas vs aleatoreas En los ANOVA(s), podemos ver dos tipos principales de variables, las cuales son importantes de diferenciar * Variables fijas: Se espera que tengan una influencia predecible y sistemática en sobre lo que queremos explicar. Además usan todos los niveles de un factor (Ejemplo genero) + Uso en R: A + B * Variables aleatorias: Se espera que su influencia sea impredecible e idiosincratica. Además no se usan todos los niveles de un factor (todos los individuos) A + Error(B) Si volvemos al ejemplo que hemos trabajado ya en clase, en el cual tratamos cada planta como un factor anidado, podemos decir que estas plantas son una variable aleatoria ## ## Error: Type ## Df Sum Sq Mean Sq ## Type 1 3366 3366 ## ## Error: Type:Plant ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Treatment 1 988.1 988.1 27.949 0.00074 *** ## Type:Treatment 1 225.7 225.7 6.385 0.03543 * ## Residuals 8 282.8 35.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Error: Within ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Residuals 72 4845 67.29 6.2.1 Más casos y resumen Trabajaremos con un caso hipotético donde \\(Y\\) es la variable a explicar y todo el resto (\\(A\\), \\(B\\) y \\(X\\)) son variables explicativas en la base de datos d 6.2.1.1 ANOVA Simple 6.2.1.2 ANOVA con interacciones Igual a 6.2.1.3 Anovas anidados y otros casos más complejos B anidado en A A es una variable aleatoria pero B esta anidada en A B y X interactuan dentro de niveles aleatorios de A 6.3 Referencias Referencias "],
["Refs.html", "Práctico 7 Referencias", " Práctico 7 Referencias "]
]
