--- 
title: "Practicos de Bioestadística 2"
author: "Derek Corcoran"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib]
biblio-style: apalike
link-citations: yes
description: "Este libro es una compañia al curso BIO4022, análisis y manipulación de datos en R"
---

# Requerimientos {-}

Para comenzar el trabajo se necesita la última versión de R y RStudio [@R-base].También se requiere de los paquetes *pacman*, *rmarkdown*, *tidyverse* y *tinytex*. Si no se ha usado R o RStudio anteriormente, el siguiente video muestra cómo instalar ambos programas y los paquetes necesarios para este curso en el siguiente [link](https://youtu.be/RtkCAKXsVbw).

<iframe width="560" height="315" src="https://www.youtube.com/embed/RtkCAKXsVbw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

El código para la instalación de esos paquetes es el siguiente:

```{r eval=FALSE}
install.packages("pacman", "rmarkdown", "tidyverse", "tinytex")
```


En caso de necesitar ayuda para la instalación, contactarse con el instructor del curso.

## Antes de comenzar

Si nunca se ha trabajado con `R` antes de este curso, una buena herramienta es provista por el paquete [Swirl](http://swirlstats.com/students.html) [@Kross2017]. Si deseas estar más preparado para el curso, realiza los primeros 7 módulos del programa *R Programming: The basics of programming in R* que incluye:

* Basic Building Blocks
* Workspace and Files
* Sequences of Numbers
* Vectors
* Missing Values
* Subsetting Vectors
* Matrices and Data Frames


El siguiente link muestra un video explicativo de cómo usar el paquete swirl [Video](https://youtu.be/w6L7Ye18yPE)

<iframe width="560" height="315" src="https://www.youtube.com/embed/w6L7Ye18yPE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

## Descripción del práctico

Los prácticos de este curso se enfocan en aprender a realizar de manera práctica los conceptos enseñados en el cuso, pero además, usando herramientas interactivas y/o programáticas, el profundizar el entendimiento de ciertos conceptos teóricos y filosóficos del curso.

##  Objetivos del práctico

1. Aprender el uso de R como ambiente estadístico de limpieza, exploración, visualización de datos.

2. Conocer y aplicar de manera aplicada los conceptos enseñados en el curso de Bioestadística 2.

3. Aprender buenas prácticas de recolección y estandarización de bases de datos, con la finalidad de optimizar el análisis de datos y la revisión de éstas por pares.

4. Realizar análisis críticos de la naturaleza de los datos al realizar análisis exploratorios, que permitirán determinar la mejor forma de comprobar hipótesis asociadas a estas bases de datos.

## Contenidos

+ Capítulo \@ref(Explorando) *Análisis exploratorio y el primer ANOVA*: En este capítulo se aprenderá a cómo explorar, resumir y visualizar una base de datos utilizando el paquete tidyverse [@WickhamTidy2017], además se realizarán un análisis básico de ANOVA

+ Capítulo \@ref(Supuestos) *Supuestos de ANOVA y mínimos cuadrados*

+ Capítulo \@ref(Poder) *Análisis de poder y primera tarea*

+ Capítulo \@ref(Refs) *Referencias*

+ Capítulo \@ref(t-student) *T de student*

+ Capítulo \@ref(posthoc) *Tests posthoc*

+ Capítulo \@ref(Formula) *Como formular tu ANOVA*


## Metodología

Clases prácticas donde cada estudiante trabajará con datos entregados para desarrollar análisis de datos. Además, se deberán generar informes, en base al trabajo con sus datos.

##  Evaluación

El trabajo práctico de este ramo es un 20% de la nota final del curso, y es obligatorio ir a todos los trabajos prácticos para pasar el ramo.

Durante los primeros 15 minutos se tomará un control. Pasado ese período, no se acepta la entrega de controles, recibiendo calificación 1. La ausencia a los trabajos prácticos puede ser causal de reprobación del curso. Ademas de los controles habrán trabajos de investigación.
 
La nota final de los practicos se evaluará de la siguiente forma:
 
* Tests de entrada: 60%
* Trabajos: 40%


## Presentación de introducción

Para la introducción de los prácticos seguiremos un a presentación que se encuentra en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase1/Clase1.html)

Si no has conseguido instalar `R`, puedes seguir el práctico usando la siguiente [guía interactiva](http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Interactivo1/)

Puedes ver la clase de nuevo en el siguiente video o clickeando en este [link](https://youtu.be/VVqUmAcYvVY)

<iframe width="560" height="315" src="https://www.youtube.com/embed/VVqUmAcYvVY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<!--chapter:end:index.Rmd-->

# Exploración de datos y tu primer ANOVA {#Explorando}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
```

## Paquetes necesarios para este práctico

Para este capitulo necesitas tener instalado el paquete tidyverse. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase2/Clase2.html). El video de la clase se encuentra disponible en este [link](https://youtu.be/DM2U19a1y4s).


<iframe width="560" height="315" src="https://www.youtube.com/embed/DM2U19a1y4s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Actividad 1 Educación en Chile

En esta actividad exploraremos los resultados de la PSU en Chile para el año 2017. Pueden encontrar la base de datos original en [Data Chile](https://es.datachile.io/geo/chile#education).

Trataremos de determinar, usando el puntaje de la PSU como medida, si existen brechas en la educación chilena por tipo de institución. Para ello, primero trabajaremos realizando análisis exploratorios en base a gráficos y tablas resumen usando funciones del paquete *tidyverse* [@WickhamTidy2017] en R.

La base de datos *EducacionChile.csv* se encuentra disponible en webcursos o en <https://es.datachile.io/geo/chile#education>.

### Tablas resumen de los datos:

Lo primero que deben hacer es generar una tabla resumen usando el *tidyverse* usando las funciones *group_by* para agrupar por variables y *summarize* para resumir los datos, dentro de summarize podemos usar variables como:

* **mean()** promedio
* **sd()** desviación estándar
* **n()** número de muestras

a modo de ejemplo vemos la tabla \@ref(tab:MediaIris) mostrando la media y número de muestras con la base de datos iris:

```{r, echo=TRUE}
data("iris")
Table <- group_by(iris, Species) %>% summarize(Promedio = mean(Petal.Length), N = n())
```

```{r, echo=TRUE, eval=FALSE}
knitr::kable(Table)
```

```{r MediaIris, echo=FALSE}
knitr::kable(Table, caption = "Resumen con la media y número de muestras del largo de pétalo de las flores de tres especies del género Iris", booktabs = TRUE)
```

Basado en el resumen ¿Qué podemos decir de estos datos de educación en Chile?

### Visualización de datos con ggplot2 (tidyverse)

El paquete *ggplot2* [@WickhamGG2016] es una poderosa herramienta para graficar datos. Si desean ahondar en el uso de este paquete, pueden ver el siguiente link <http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/>. En este caso, aprenderemos a graficar *boxplots* y *jitterplots*, dos opciones para visualizar una variable categórica versus una cuantitativa. 

#### Uso del ggplot2

Su función principal es *ggplot*, luego de cada función usaremos el símbolo **+** como usábamos el pipeline (%>%).

Primero usamos la función ggplot para determinar la base de datos y variables, acá las variables siempre van dentro de la función aes

```{r, eval=FALSE, echo=TRUE}
ggplot(MiBaseDeDatos, aes(x = VariableX, y = VariableY)) 
```

Luego agregamos el tipo de gráfico que queremos para nuestra figura usando el **+** como pipeline

```{r, eval=FALSE, echo=TRUE}
ggplot(MiBaseDeDatos, aes(x = VariableX, y = VariableY)) + geom_boxplot()
```

#### Ejemplo usando la base de datos iris

##### Boxplot

El siguiente código muestra como graficar un boxplot para la base de datos iris, la cual esta en R. En este caso graficaremos el largo del pétalo para cada especie (Figura \@ref(fig:BoxplotIris)).

```{r, echo=TRUE, eval=FALSE}
data("iris")
ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot()
```

```{r BoxplotIris, echo=FALSE, fig.cap="Box plot del largo de petalo de tres especies del género Iris"}
ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot()
```

En los Box Plots tenemos 4 visualizaciones:

* Mediana (linea gruesa)
* Caja (Cuantiles 25% y 75%)
* Bigotes (intervalo de confianza del 95%)
* Puntos Outlayers

Realice un boxplot de los datos de la educación de Chile, ¿Qué nos dice esto de los datos?

##### Jitter plot

El jitter plot suma un punto por cada observación, lo cual nos permite entender un poco más la naturaleza de los datos. En general se le agrega a un box plot para tener mayor claridad en los datos (Figura \@ref(fig:JitterIris)).

```{r, echo=TRUE, eval=FALSE}
data("iris")
ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot() + geom_jitter(aes(color = Species))
```

```{r JitterIris, echo=FALSE, fig.cap="Box plot y jitter plot juntos para el largo de petalo de tres especies del género Iris"}
data("iris")
ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot() + geom_jitter(aes(color = Species))
```


## Actividad 2 Captación de CO2 en plantas    

Utilizaremos base de datos $CO_2$ [@potvin1990statistical] enviada al curso. Esta base de datos, también presente en R, tiene las siguientes variables

* **Plant**: Identidad de cada planta
* **Type**: Variedad de la planta (subespecie Quebec o Mississippi)
* **Treatment**: Tratamiento de la planta, algunas fueron enfriadas la noche anterior (Chilled)
* **conc**: Concentración ambiental de $CO_2$
* **Uptake**: Captación de $CO_2$ para cada planta en cada día

¿Hay diferencias entre la captación de $CO_2$ en plantas tratadas y no tratadas?

* Genere tablas resumenes que le permitan explorar esta pregunta
    + ¿Existen variables que puedan confundir el resultado? ¿como trataría los datos para lidiar con esto?
* Genere gráficos exploratorios para contestar esta pregunta

## Actividad 3 Mi primer ANOVA

### antes de empezar a entender el ANOVA

El ANOVA compara medias entre grupos, lo principal es la comparación entre los cuadrados de los residuales intergrupos, y los residuales intragrupos, los primeros son los cuadrados de la diferencia entre las medias de todas las observaciones ($\tilde{x}_t$) y las medias de cada grupo $\tilde{x}_g$ al cuadrado multiplicado por el número de observaciones totales (ver ecuación \@ref(eq:intergrups)), cambia las medias del simlador de anova a continuacion y selecciona los errores intergrupos y ve como cambian.

\begin{equation} 
  \textrm{Errores_inter_factor} = n \times \sum{(\tilde{x}_t - \tilde{x}_g)^2}
  (\#eq:intergrups)
\end{equation} 

los residuales intra grupos son la diferencia entre cada observación $x_{i,g}$ del grupo $g$ y las medias del grupo respectivo (ver ecuación \@ref(eq:intragrups)), cambia las medias del simlador de anova a continuacion y selecciona los errores intragrupos y ve como cambian

\begin{equation} 
  \textrm{Errores_intra_factor} = \sum{(\tilde{x}_g - x_{i,g})^2}
  (\#eq:intragrups)
\end{equation} 


#### Simulador de ANOVA

```{r}
knitr::include_app("http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Shiny2/", height = "1500px")
```


### Como hacer un ANOVA en R

En *R* todos los modelos tienen la siguiente estructura **Funcion(y ~ x1 + x2 + ... + xn, data = MisDatos)**, donde la **Funcion** dice el modelo que queremos realizar (por ejemplo ANOVA, regresión lineal, modelos mixtos, etc.), **y** es la variable que queremos explicar, **x1** a **xn** son las variables explicativas, **~** es un símbolo que debe ser leído como explicado por y finalmente **data** es la base de datos que queremos utilizar, en un ANOVA (análisis de varianza), la función en cuestión es aov. 

En el siguiente código vemos si el largo del pétalo de las flores del género *Iris*, pueden ser explicados por la especie a la que estas plantas pertenecen, por lo que generamos un modelo llamado *Primer.Anova* con la función **aov**.

```{r, echo = TRUE}
Primer.Anova <- aov(Petal.Length ~ Species, data = iris)
```

Para acceder a la tabla de resultados utilizamos la función **summary**

```{r}
summary(Primer.Anova)
```

Si establecemos el valor de alfa en 0.05 y al ver en la tabla que el valor de p es menor a alfa, rechazamos la hipótesis nula de que las medias son iguales, y decidimos que la media del largo de pétalo es distinta entre las especies.

### Ejercicio

Determine si para la base de datos **CO2** la captación de $CO_2$ es distinto entre plantas con tratamiento de enfriamiento y sin enfriamiento.



<!--chapter:end:01Guia2.Rmd-->

# Supuestos de ANOVA y mínimos cuadrados {#Supuestos}

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
```

## Paquetes necesarios para este práctico

Para este capitulo necesitas tener instalado el paquete *tidyverse*, también ayuda tener el paquete *broom*. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase3/Clase3.html). El video de la clase se encuentra disponible en este [link](https://youtu.be/Fgio8lDfDpo).

<iframe width="560" height="315" src="https://www.youtube.com/embed/Fgio8lDfDpo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Objetivos de este práctico

- Entender los supuestos de un ANOVA de una vía (independencia, aleatoriedad, homocedasticidad y normalidad)
- Entender el concepto de mínimos cuadrados
- Saber cuando realizar un ANOVA e interpretar sus resultados

## Actividad 1 Sueño en mamíferos

En esta actividad intentaremos ver si hay diferencias en horas de sueño en mamíferos por Orden o dieta. Los datos fueron extraídos del trabajo de @savage2007quantitative y están incorporados en la base de datos de *ggplot2* con el nombre de *msleep*, pero estarán en webcursos en formato csv de todas formas. Para la guía los ejemplos se generarán en base a la base de datos *InsectSprays* que está en *R* y que fue extraída de @beall1942transformation, en la cual se testean la efectividad de insecticidas en Spray en la abundancia de insectos en plantaciones. Y en la base de datos *iris* que ya fue entregada, en la que se miden distintas características florales de especies del genero *Iris* [@anderson1935irises].

### Homogeneidad de varianza

#### Inspección visual

Lo primero que intentaremos explorar de forma visual y a partir de tests si es que hay homogeneidad de varianza, para esto usaremos boxplots, y jitter plots (Figura \@ref(fig:Visual)), lo cual ya hemos hecho anteriormente:

```{r, echo=TRUE, eval = FALSE}
ggplot(InsectSprays, aes(x = spray, y = count)) + geom_boxplot() + geom_jitter(aes(color = spray)) 
```

```{r Visual, echo=FALSE, fig.cap= "Cuenta de insectos según tipo de insecticida"}
ggplot(InsectSprays, aes(x = spray, y = count)) + geom_boxplot() + geom_jitter(aes(color = spray)) 
```


Para explorar visualmente si existe homogeneidad de varianza, se compraran las cajas y bigotes de los boxplots y se espera que tengan (Mas o menos distintos tamaños).

#### Test de Bartlett

Para realizar un test de homogeneidad de varianza se realiza el test de bartlett [@bartlett1937properties], en este se usa nuestra conocida formula *y ~ x*, esto es, y explicado por x junto a la función *bartlett.test*. Para nuestro caso usaríamos:

```{r}
bartlett.test(count ~ spray, data = InsectSprays)
```

Como en este caso, no el valor de p es menor a 0.05, decimos que no hay homogeneidad de varianza, por lo que no podemos hacer el test.

### Normalidad de los residuales

En el caso de la base de datos *iris*, demostraremos inmediatamente que si hay homogeneidad de varianza en el ancho del sépalo (Figura \@ref(fig:IrisBox)):

```{r IrisBox, echo=FALSE, fig.cap= "Ancho de sépalo según especie del género Iris"}
ggplot(iris, aes(x = Species, y = Sepal.Width)) + geom_boxplot() + geom_jitter(aes(color = Species)) 
```

```{r, echo = FALSE}
bartlett.test(Sepal.Width ~ Species, data = iris)
```

Debido a ello, podemos testar si los residuales tienen una distribución normalidad de los residuales, para esto lo primero que debemos hacer es un ANOVA, como fue explicado en el práctico anterior y guardar este objeto con un nombre:

```{r}
ANOVA.Iris <- aov(Sepal.Width ~ Species, data = iris)
```

#### Extracción de los residuales del modelo

Para extraer los residuales, podemos hacerlo de dos formas, si solo queremos un vector de sus valores, podemos extraerlo desde el modelo mismo utilizando *$residuals*. Si queremos guardarlo en un dataframe mas completo podemos utilizar la función *augment* del paquete *broom*.

```{r}
Residuales <- ANOVA.Iris$residuals
library(broom)
Resultados <- augment(ANOVA.Iris)
```

La segunda opción nos entregará más información que podremos utilizar más tarde, pero ambas sirven para testear normalidad, la siguiente tabla muestra las primeras 6 observaciones generadas por la función *augment*, donde *resid*, son los residuales (Ver tabla \@ref(tab:TabResid).

```{r TabResid, echo =FALSE}
knitr::kable(head(Resultados), caption= "primeras 6 observaciones del dataframe resultante de augment", digits = 3)
```

#### Inspección visual de los residuales

Existen dos formas de visualizar los residuales para determinar si la distribución de estos es o no es normal, histogramas y el qqplot. 

##### Histograma

Los histogramas nos darán una representación visual para tratar de entender si la distribución es normal, para esto, solo necesitamos usar el comando *hist*, seguido del vector de los residuales, este es el comando para hacer el histograma (Figura \@ref(fig:histogram)) con cualquiera de las dos bases de datos, el resultado debiera ser el mismo:

```{r, echo=TRUE, eval=FALSE}
hist(Residuales)
hist(Resultados$.resid)
```

```{r histogram, echo=FALSE, fig.cap= "Histograma de los resiudales del modelo ANOVA"}
hist(Residuales)
```

##### QQplot

El qq plot es otra forma visual de establecer si los residuales son o no son normales, para esto, lo esperado es que la gráfica resultante sea una diagonal lo mas recta posible, para esto usaremos la función *qqnorm*, con nuestros residuales, de nuevo, podemos usar cualquiera de las dos versiones de nuestros datos:

```{r, echo=TRUE, eval=FALSE}
qqnorm(Residuales)
qqnorm(Resultados$.resid)
```

```{r, echo=FALSE, fig.cap= "qqplot de los resiudales del modelo ANOVA"}
qqnorm(Residuales)
```

#### Test de Shapiro para determinar normalidad

La forma más sencilla de determinar normalidad es usando el test de Shapiro-Wilk de normalidad [@royston1995remark]. Al igual que el test de Bartlett, si el valor de p es menor a 0.05, determinamos que la distribución de los datos no son normales, la función en *R* para este test es *shapiro.test*, y al igual que en los casos anteriores de *hist* y *qqpot*, solo necesitamos de usar un vector de residuales para ver el resultado del test. En nuestro caso:

```{r, echo=TRUE, eval=FALSE}
shapiro.test(Residuales)
shapiro.test(Resultados$.resid)
```

```{r, echo=FALSE, fig.cap= "qqplot de los resiudales del modelo ANOVA"}
shapiro.test(Residuales)
```

Ya que el valor de p es menor a 0.05, podemos decir que la distribución de nuestros residuales es normal, y por lo tanto el test cumple con los supuestos, y esto hace que sea valido el ANOVA, por lo que podemos ver nuestros resultados. La homogeneidad de Varianza es mas importante que la normalidad de residuales para estos casos, para ejemplos de lo que se debe hacer si se viola la normalidad ver @lix1996consequences

## Actividad 2 Suma de cuadrados

Tanto los ANOVAS como las regresiones lineales se basan en minimizar la suma de cuadrados, es la suma de los cuadrados de los errores o residuales.

### ¿Que es el error? ¿Por qué al cuadrado??


```{r, echo = FALSE, fig.cap= "Errores de una regresión lineal ejemplificados con la linea entre el valor predicho y el observado"}
testy <- augment(lm(mpg ~ wt, data =mtcars))
ggplot(testy, aes(x = wt, y = mpg)) + geom_point() + geom_smooth(method="lm") + geom_segment(aes(xend = wt, yend = .fitted)) + theme_classic()
```

En la figura y en la formula vemos ejemplificado que es el error, también conocido como residual, este es simplemente el valor observado

$$Observado - Predicho$$

El objetivo de todo modelo es el de minimizar estos errores, al ajustar el mejor modelo posible.

Los errores siempre se calculan al cuadrado, discutiremos por que en clase

$$\sum_{i=1}^{n} (Observado - Predicho)^2$$

```{r}
library(knitr)
include_app(url = "http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Shiny1/", height = "800px")
```



## Referencias

<!--chapter:end:02Guia3.Rmd-->

# Análisis de poder {#Poder}

Para este capitulo necesitas tener instalado el paquete *pwr2*, también ayuda tener el paquete *broom*. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase4/Clase4.html).

El video de la clase se encuentra disponible en este [link](https://youtu.be/WoJ3wvFTejU).

<iframe width="560" height="315" src="https://www.youtube.com/embed/WoJ3wvFTejU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
```
## Obejtivos del práctico

* Entender cálculos de poder en base a matriz de confusión
* Primera tarea de práctico

## Matriz de confusión

La matriz de confusión es una herramienta de toma de decisiones, en el caso especial de la toma de decisiones tenemos la siguiente matriz de confusión (Tabla \@ref(tab:errores))

```{r}
library(knitr)
Coso <- data.frame(Hipotesis.Nula = c("No hay error", "Error tipo 1"), Hipostesis.alternativa =c("Error tipo 2", "No hay error"))
colnames(Coso) <- c("Hipótesis nula cierta", "Hipótesis alternativa cierta")
rownames(Coso) <- c("Acepto hipótesis nula", "Acepto hipótesis alternativa")

```

```{r errores}
kable(Coso, caption = "Tabla de confusión de errores")

```


Esto puede ser fácilmente ejemplificado con el problema de una alarma de humo (tabla\@ref(tab:Confucion)), en este caso cuando la alarma suena y no hay fuego y suena la alarma tenemos un error de tipo 1, en cambio si hay fuego y la alarma no suena tenemos un error de tipo 2

```{r}
Coso <- data.frame(No.fuego = c("No hay error", "Error tipo 1"), Fuego =c("Error tipo 2", "No hay error"))
colnames(Coso) <- c("No hay fuego", "Hay fuego")
rownames(Coso) <- c("No suena alarma", "Suena alarma")
```


```{r Confucion, echo=FALSE}
kable(Coso, booktabs = TRUE, caption = "Matriz de confusión de una alarma de incendio")
```

### Poder y matriz de confusión

* Probabilidad de que suene la alarma cuando no hay fuego
    + $\alpha$ usualmente 5% 
    + una de cada 20 alarmas es falsa
    + ¿Cuál es el $\alpha$ de una alarma de auto?
* Probabilidad de que no suene la alarma cuando hay fuego
    + $\beta$ si es 10% uno de cada 10 fuegos no es detectado
    + poder es $1-\beta$ confianza de que fuegos son detectados

## Calculo de poder en R

Para hacer cálculos de poder en ANOVAS de una y dos vías en *R*, utilizamos el paquete *pwr2* [@Pengcheng2017]. En este paquete podemos utilizar la función *pwr.1way* para determinar el poder de un ANOVA de una vía, los argumentos de esta función son:

* *K*: El número de grupos a testear
* *n*: Número de individuos por grupo
* *Alpha*: Nivel de significancia
* *Delta*: Valor mínimo a detectar
* *Sigma*: Desviación estándar de la muestra

Para cálculos precisos de n necesarios para muestras usar la siguiente app

```{r}
knitr::include_app("http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Shiny3/", height = "600px")
```


<!--chapter:end:03Guia4.Rmd-->

# Prueba t de Student {#t-student}

Para este capitulo necesitas tener instalado el paquete *tidyverse*, también ayuda tener el paquete *broom*. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase5/Clase5.html). Además hay una forma interactiva de esta guía en el siguiente [link](http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Test/Interactivo5/).

El video de la clase se encuentra disponible en este [link](https://youtu.be/WoJ3wvFTejU?t=2279).

<iframe width="560" height="315" src="https://www.youtube.com/embed/WoJ3wvFTejU?start=2279" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
```

Puedes encontrar una versión interactiva de esta guía [aquí](http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Interactivo5/).

La prueba t de student fue desarrollada por Gosset cuando trabajaba para la cervecería Guinness [@student1908probable]. Esta prueba permite comparar las medias de una muestra con la media teórica de una población, o comparar dos poblaciones. Una de las características de la prueba de student, es que permite la alternativa de ver si dos medias son diferentes o, si uno busca más confianza determinar si una media es mayor, o menor que otra. Para la prueba t de Student, se determina un valor de t, usando la siguiente formula (ecuación \@ref(eq:tStud)):

\begin{equation} 
  t = \frac{(\bar{x} - \mu)/(\frac{\sigma}{\sqrt{n}})}{s}
  (\#eq:tStud)
\end{equation} 

El estadístico $t$ posee un valor de p asociado dependiendo de los grados de libertad de la prueba.

### Pruebas de una muestra

Las pruebas de una muestra nos permiten poner a prueba si la media de una población son distintas a una media teórica. Como ejemplo veremos el caso de las erupciones del géiser *Old Faithful*, localizado en el Parque Nacional Yellowstone. Un guarda-parque del lugar dice que este géiser erupta cada 1 hora. Por suerte *R* posee una base de datos de @azzalini1990look llamada *faithfull*, la cual utilizaremos para determinar si esto es cierto o no usando la función `t.test`. Esta base de datos tiene dos columnas *eruptions*, que muestra la duración en minutos de cada erupción y *waiting* que presenta la espera en minutos entre erupciones.

Cuando usamos esta función con una muestra necesitamos llenar 2 argumentos:

* **x:** Un vector con los valores numéricos de a poner a prueba
* **mu:** La media teórica a poner a prueba
* **alternative:** Puede ser "two.sided", "less" o "greater", dependiendo de si uno quiere probar que la muestra posee una media distinta, menor o mayor que la media teórica.

En este caso haríamos lo siguiente

```{r, echo=TRUE}
data("faithful")
t.test(x = faithful$waiting, mu = 60, alternative = "two.sided")
```

En este caso el valor de p nos dice que la media es diferente a 60.

#### Ejercicio 1

La base de datos *airquality* (incorporada como ejemplo en **R**), muestra entre otras variables las partículas de ozono en Nueva York, cada día de Mayo a Septiembre de 1973 entre las 13:00 y las 15:00 [@chambers35graphical]. Supongamos que ustedes están a cargo de una agencia ambiental, y están estudiando en que meses deben reducir la actividad vehicular de Nueva York. Para esto planean disminuir a la mitad los pasajes del metro de Nueva York todos los meses que en promedio tengan sobre 55 ppb. Para esto deben comprobar estadisticamente que el mes en que harán esto tiene promedios sobre 55.

### Pruebas de dos muestras

Las pruebas de dos muestras nos permiten ver si hay diferencias significativas entre las medias de dos muestras. En la base de datos `mtcars`, hay una columna que determina si los vehículos son de cambios manuales o automáticos. En este caso 0 significa automático y 1 significa manual. En la figura \@ref(fig:autom) podemos ver una inspección gráfica de las posibles diferencias.

```{r autom, fig.cap="Comparación de eficiencia entre vehiculos automaticos y manuales"}
data("mtcars")
mt <- mtcars
mt$am <- ifelse(mtcars$am  == 0, "automatico", "manual")
mt <- as.data.frame(mt)
ggplot(mt, aes(x = am, y = mpg)) + geom_boxplot() + geom_jitter(aes(color = am))
```

Para hacer la comparación debemos agregar el argumento `var.equal` el cual en este caso asumiremos que es verdad, ya que en la próxima sección veremos los supuestos de la prueba t y las consecuencias de las violaciones de estos supuestos. En este caso podemos usar el símbolo `~` a ser leído como explicado por para la prueba t de dos muestras.

```{r, echo=TRUE}
t.test(mpg ~ am, data = mtcars, var.equal =TRUE)
```

En este caso se determinaría que los vehículos manuales (am = 1), son más eficientes que sus contra-partes automáticas.

#### Ejercicio 2

Para el siguiente ejercicio usaremos la base de datos `BeerDark` disponible en webcursos o en el siguiente [link](https://archive.org/download/BeerDark/BeerDark.csv). Esta base de datos posee 7 columnas, pero usaremos solo 4 de ellas:

* **Estilo:** Separa las cervezas entre Porters y Stouts
* **Grado_Alcoholico:** El grado alcohólico de las cervezas
* **Amargor:** Valor IBU (International Bittering Units), a mayor valor más amarga la cerveza
* **Color:** A mayor valor más oscura la cerveza.

Determinar si las cervezas Porter y Stouts son distintas en grado alcohólico, amargor y/o color. 

## Supuestos de la prueba de t y alternativas

Los supuestos de la t de student son las siguientes [@boneau1960effects]

* Independencia de las observaciones
* Distribución normal de los datos en cada grupo
* Homogeneidad de varianza

### Prueba de una muestra

Como siempre la independencia de las muestras es algo que solo puede determinarse en base a el diseño del muestreo, y por otro lado, al haber solo una muestra, la homogeneidad de varianza no es un problema, en este caso solo podemos ver si la distribución es normal. Volviendo a nuestro ejemplo de una muestra, con la base de datos `faithfull`, veamos en base a un histograma (figura \@ref(fig:Hist)), qqplot (figura \@ref(fig:QQ)) y test de shapiro, si los datos son normales o no:

```{r Hist, echo = TRUE, fig.cap= "Histograma de los minutos de espera de el géiser Old Fiathful"}
hist(faithful$waiting, xlab = "Minutos de espera entre erupciones")
```

```{r QQ, echo = TRUE, fig.cap= "QQplot de los minutos de espera de el géiser Old Fiathful"}
qqnorm(faithful$waiting)
```


```{r, echo = TRUE}
shapiro.test(faithful$waiting)
```

Como vemos en la figura 2, los datos no se ven normales, incluso se ven bimodales, lo cual significa que tiene 2 picos, en este caso uno al rededor de los 52 minutos y otro al rededor de los 85 minutos de espera (recordemos que la función `hist`, automáticamente usa el algoritmo de @sturges1926choice, para determinar como dividir los datos y obtener el mejor histograma). Nuestras sospechas de no normalidad son confirmadas al ver el qqplot, que no sigue para nada la diagonal, y es reafirmado por el test de shapiro, cuyo valor mucho menor a 0.05, nos dice que la distribución no es normal. Dado esto, debemos apelar a un test de distribución libre como el de *Mann-Whitney*, la cual se realiza con la función `wilcox.test`, de la misma forma que es utilizada la función `t.test`, por lo tanto para nuestro ejemplo usamos:

```{r, echo=TRUE}
data("faithful")
wilcox.test(x = faithful$waiting, mu = 60, alternative = "two.sided")
```

Que en este caso nos lleva a la misma conclusión que nuestro ejemplo anterior.

### Prueba de dos muestras

Para una prueba de dos muestras, podemos testear tanto la homogeneidad de varianza como la normalidad, para ver las dos cosas al mismo tiempo podemos usar un gráfico de violín (figura \@ref(fig:Violin)). En este caso, las distribuciones no se ven muy diferentes a la normalidad, pero las varianzas se ven un tanto distintas, podemos seguir explorando esto visualmente usando la función `hist` previamente generando dos data frames, uno para autos automático y otro para manuales. 

```{r, echo = TRUE}
data("mtcars")
mt <- mtcars
mt$am <- ifelse(mtcars$am  == 0, "automatico", "manual")
mt <- as.data.frame(mt)
```


```{r Violin, echo = TRUE, fig.cap="Comparación de distribuciones y varianzas de los vehiculos automáticos "}
ggplot(mt, aes(x = am, y = mpg)) + geom_violin()
```

En este caso, las distribuciones no se ven muy diferentes a la normalidad, pero las varianzas se ven un tanto distintas, podemos seguir explorando esto separando los datos en vehículos automáticos y manuales para hacer histogramas, en este caso es importante que los ejes sean iguales, para eso en el histograma usaremos los parámetros ylim y xlim.

```{r}
manuales <- mt %>% filter(am == "manual")
```


```{r Manual, echo = TRUE, fig.cap="Histograma de vehiculos manuales"}
hist(manuales$mpg, xlim = c(10,35), ylim = c(0,5))
```

```{r}
autos <- mt %>% filter(am == "automatico")
```


```{r Auto, echo = TRUE, fig.cap="Histograma de vehiculos automáticos"}
hist(autos$mpg, xlim = c(10,35), ylim = c(0,5))
```

Como vemos, los vehículos manuales no parecen tener distribución normal como se ve en la figura \@ref(fig:Manual), esto podemos comprobarlo con el qqlot de los mismos datos (figura \@ref(fig:qqManual))

```{r qqManual, echo = TRUE, fig.cap= "QQplot de eficiencia de vehiculos con cambios manuales"}
qqnorm(manuales$mpg)
```

#### Ejercicio 3

Como siempre la independencia de las muestras es algo que solo puede determinarse en base a el diseño del muestreo, y por otro lado, al haber solo una muestra, la homogeneidad de varianza no es un problema, en este caso solo podemos ver si la distribución es normal. Volviendo a nuestro ejercicio de una muestra, con la base de datos `airquality`, evalúe basado en histograma, qqplot y test de shapiro si se debe revaluar la hipótesis para los meses de julio y agosto

Para una prueba de dos muestras, podemos testear tanto la homogeneidad de varianza como la normalidad, para ver las dos cosas al mismo tiempo podemos usar un gráfico de violín `geom_violin` en *ggplot2*, lo cual puede seguir siendo explorando esto visualmente usando la función `hist` generando dos data frames, uno por cada clase de datos.

Evalúe si es necesario revaluar la hipótesis de que el amargor es distinto entre ambos estilos de cerveza

## Bibliografía

<!--chapter:end:04Guia5.Rmd-->

# Comparaciones posthoc y diseños anidados {#posthoc}

Para este capitulo necesitas tener instalado el paquete *tidyverse*, también ayuda tener el paquete *broom*. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase6/Clase6.html)

El video de la clase se encuentra disponible en este [link](https://youtu.be/tjj1EiBg6k0).

<iframe width="560" height="315" src="https://www.youtube.com/embed/tjj1EiBg6k0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
```

## Comparaciones posthoc

Como ya vimos en los prácticos anteriores, un ANOVA sólo puede decirnos si hay diferencias entre grupos, sin embargo no nos dira entre que grupos hay diferencias, es para esto que existen las pruebas posthoc. En el práctico de hoy veremos dos tipos de comparaciones posthoc, la prueba honesta de diferencias significativas de Tukey (función `TukeyHSD` en R), y los ajustes de valores de p para comparaciones multiples (función `pairwise.t.test` en R), de las cuales la de Bonferroni es la más habitual.

### Prueba honesta de diferencias significativas de Tukey

#### Ejemplo ancho de spealo en el genero Iris

Como vimos en nuestro ejemplo de la guía número 3 (Análisis exploratorio y el primer ANOVA), el ANOVA para determinar si hay diferencias en el ancho de sépalo entre las diferentes especies del genero *Iris*, son significativas:

```{r, echo = TRUE}
summary(aov(Sepal.Width ~ Species, data = iris))
```

Pero este análisis no nos dice en tre que especies encontramos estas diferencias, para esto, podemos realizar una prueba honesta de diferencias significativas de Tukey, para esto utilizamos la función `TukeyHSD` y usamos como argumento un ANOVA ya ajustado

```{r, echo = TRUE}
AnovaSepalo <- aov(Sepal.Width ~ Species, data = iris)
TukeyHSD(AnovaSepalo)
```

### Ajustes de valores de p para comparaciones multiples

#### Ajuste de Bonferroni

Cuando realizamos multiples comparaciones pareadas entre grupos, la probabilidad de encontrar diferencias significativas cuando no los hay (error tipo I), aumenta a una tasa dada por la siguiente fórmula:

$$\alpha_{ajustado} = 1 - (1 -\alpha)^n$$
Donde $\alpha$ es la probabilidad de cometer un error tipo I que estamos dispuestos a aceptar (tipicamente 0.05), y $n$ es el numero de pruebas independientes a realizar.

Con esto según el ajuste de Bonferroni, nuestro p critico para determinar diferencias significativas cambia segun la siguiente fórmula [@tukey1977some]

$$p-critico_{ajustado} = 1 - (1 -\alpha)^{1/n}$$
El ajuste de Bonferroni, sin embargo al disminuir los errores de tipo I, aumenta los errores de tipo II [@morgan2007p]. En ese sentido, la función de R `pairwise.t.test`, nos permite utilizar varios ajustes menos conservadores incluyendo los de Holm (1979), Hochberg (1988), Hommel (1988), Benjamini & Hochberg (1995) o el de Benjamini & Yekutieli (2001) 

#### Ejemplo ancho de spealo en el genero Iris

Volviendo al mismo ejemplo que usamos en la prueba de Tukey, mostraremos los valores de p determinados para comparaciones multiples de el ancho de sepalo sin ajuste y con diversos ajustes que encontramos en el la función `pairwise.t.test`

##### Sin ajuste

```{r, echo=TRUE}
pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = "none")
```

##### Ajuste de Bonferroni

```{r, echo=TRUE}
pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = "bonf")
```

##### Ajuste de Holm

```{r, echo=TRUE}
pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = "holm")
```

##### Ajuste de Hommel

```{r, echo=TRUE}
pairwise.t.test(x = airquality$Ozone, g = airquality$Month, p.adj = "hommel")
```

##### Diferencias

Se observa como sin ajustar hay 6 pares de meses que tienen diferencias, en contraste con 4 pares de meses con el ajuste de Bonferroni, y 5 con los otros métodos de ajuste de valor de p.

## Diseños anidados

Los diseños anidados ocurren cuando queremos estudiar el efecto de un factor, pero dentro de las muestras existe un segundo factor que puede afectar nuestros análisis, por ejemplo si volvemos a el caso en de la base de datos `CO2`


```{r}
Co2Real <- CO2 %>% group_by(Plant, Type, Treatment) %>% summarise(PromedioCO2 = mean(uptake))
Co2Promedio <- Co2Real %>%  group_by(Type, Treatment) %>% summarise(CO2 = mean(PromedioCO2), SD =sd(PromedioCO2))
ggplot(Co2Promedio, aes(x = Treatment, y = CO2)) + geom_line(aes(color = Type)) + geom_point(aes(color = Type)) + geom_errorbar(aes(ymin = CO2 - SD, ymax = CO2 + SD, color = Type), width = 0.1)
```


## Tarea 1

La municipalidad de *Muy muy lejano* tiene un sistema de 5 lagos muy contaminados. Se le encarga estudiar la capacidad biorremediadora de las algas unicelulares *Chlorellia fecolitica* (desde ahora alga A) y *Rhodollia coprofaga* (en adelante alga B). Para realizar el experimento y posteriormente comprar cepas para biorremediación. Con un presupuesto de 50,000 coronas, donde cada cultivo de alga cuesta 1,000 coronas. Utilizando la siguiente app realize un experimento, y luego genere un informe en formato paper donde aparezca lo siguiente:

  + Realiza un calculo de poder en base al archivo *Presamp.csv* para ver cual debiera ser tu número de mustras necesaria y explicalo
  + Establece si se cumplen los supuestos de los test a realizar y ejecuta deacurdo a tus conocimientos justificando
  + Determinar si alguna de las algas es mejor biorremediador (incluyendo comparaciones post-hoc)
  + Dentro de lo posible utiliza la menor cantidad posible de presupuesto, debes utilizar el presupuesto que te queda para proponer una medida de biorremediación



```{r}
library(knitr)
include_app(url = "http://admin.derek-corcoran-barrios.com/shiny/rstudio/sample-apps/Acuarios/", height = "800px")
```



## Referencias

<!--chapter:end:05Guia6.Rmd-->

# Como formular tu ANOVA {#Formula}

Para este capitulo necesitas tener instalado el paquete *tidyverse*, también ayuda tener el paquete *broom*. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase7/Clase7.html)


```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
options("kableExtra.html.bsTable" = T)
library(kableExtra)
```

## ANOVA(s)

Si bien el ANOVA puede ser pensado como una extensión de una prueba de T de student, es mucho más complejo que eso, existen muchos tipos de anovas y sus combinaciones, tales como:

* ANOVA
* ANOVA factorial o en bloque
* ANOVA anidado o jerarquico
* ANOVA desbalanceado

Tanta es la variedad de ANOVAS que existen muchos libros dedicados exclusivamente a la discusión de este tipo de análisis [@girden1992anova]
    
### ANOVA simple

En la versión más senilla del ANOVA, varios grupos comparten una variable que creemos que es diferente entre grupos, como por ejemplo ancho de sepalo puede ser differente entre tres especies de *Iris*, para analizar esto, usaríamos el siguiente código, lo que muestra diferencias en el ancho de sépalo entre especies, lo cual se aprecia en el gráfico 1.
    
```{r}
data(iris)
IRISANOVA <- aov(Sepal.Width ~ Species, data = iris)
summary(IRISANOVA)
```

```{r, echo=FALSE, fig.cap="Relación entre el ancho del sépalo y las especies de Iris"}
ggplot(iris, aes(x = Species, y = Sepal.Width)) + geom_boxplot(aes(fill = Species)) + theme(legend.position = "bottom") + theme_classic()
```


### ANOVA factorial

En el ANOVA factorial, más de un factor puede afectar nuestra variable respuesta. Además, estas variables pueden interactuar, haciendo que el efecto de sobre las muestras sea mas complejo que el efecto de cada variable.  Un ejemplo de análisis es la economía de combustible en `mtcars` según si es automático o manual y el número de cilindros que tiene. 

En este caso modificaremos la base de datos para que el factor am en vez de numerico sea factor:

```{r}
mt <- mtcars
mt$am <- ifelse(mt$am == 0, "Automatic", "Manual")
ANOVA.AUTO <- aov(mpg ~ am + cyl + am:cyl, data = mt)
summary(ANOVA.AUTO)
```

Aquí vemos que si hay una interacción. Las interacciones las notamos rápidamente en figuras como la que vemos en el grafico 2 imagen B, en la cual cada vez que las lineas no sean paralelas diremos que hay una interacción.

```{r, echo = FALSE, fig.cap="Relación entre el número de cilindros, transmición automática o manual, y la economía de combustible de los vehiculos, la relacion la mostramos como un boxplot (A) y como barras de errores unidas por sus medias (B), esta última interpretación permite ver gráficamente las interacciones entre factores"}
A <- ggplot(mt, aes(x = factor(cyl), y = mpg)) + geom_boxplot(aes(fill = am)) + geom_jitter(aes(color = am)) + xlab("cylinders") + theme_classic() + theme(legend.position = "bottom") + ggtitle("A")

mt <- mt %>% group_by(am, cyl) %>% summarise(MeanMPG = mean(mpg), SDMPG = sd(mpg))

B <- ggplot(mt, aes(x = factor(cyl), y = MeanMPG, group = am)) + geom_line(aes(color = am))+ geom_errorbar(aes(ymin = MeanMPG - SDMPG, ymax = MeanMPG + SDMPG, color = am), width = 0.2) + geom_point(aes(color = am)) + xlab("cylinders") + theme_classic() + theme(legend.position = "bottom") + ggtitle("B")

library(gridExtra)

grid.arrange(A, B, ncol=2)
```


### ANOVA anidado o jerarquico

En este tipo de ANOVA tenemos un factor jerarquicamente dentro de otro, por ejemplo individuos dentro de una especie, hojas dentro de un árbol o varias medidas dentro de un mismo individuo. En `R` dentro de la función `aov`, si el factor $B$ esta anidado dentro de $A$ tenemos `A/B` como una variable explicativa. Si usamos como ejemplo la de datos `CO2`, los individuos de cada subespecie estan anidados dentro de cada subespecie. Esto sería analizado con el siguiente codigo:

```{r}
ANOVAUptake <- aov(uptake  ~  Type + Treatment + Type:Treatment + Type/Plant, data=CO2)
summary(ANOVAUptake)
```


## Variables fijas vs aleatoreas

En los ANOVA(s), podemos ver dos tipos principales de variables, las cuales son importantes de diferenciar
* **Variables fijas:** Se espera que tengan una influencia predecible y sistemática en sobre lo que queremos explicar. Además usan todos los niveles de un factor (Ejemplo genero)
    + Uso en `R`: `A + B`
* **Variables aleatorias:** Se espera que su influencia sea impredecible e idiosincratica. Además no se usan todos los niveles de un factor (todos los individuos) `A + Error(B)`

Si volvemos al ejemplo que hemos trabajado ya en clase, en el cual tratamos cada planta como un factor anidado, podemos decir que estas plantas son una variable aleatoria

```{r}
ANOVAUptake <- aov(uptake  ~  Type + Treatment + Type:Treatment + Error(Type/Plant), data=CO2)
summary(ANOVAUptake)
```


### Más casos y resumen

Trabajaremos con un caso hipotético donde $Y$ es la variable a explicar y todo el resto ($A$, $B$ y $X$) son variables explicativas en la base de datos `d`

#### ANOVA Simple

```{r, eval=FALSE}
aov(Y ~ A + B, data=d)
```

#### ANOVA con interacciones

```{r, eval=FALSE}
aov(Y ~ A + B + A:B, data=d)
```
Igual a

```{r, eval = FALSE}
aov(Y ~ A * B, data=d)
```

#### Anovas anidados y otros casos más complejos

* B anidado en A

```{r, eval = FALSE}
aov(Y ~ A/B, data=d)
```

* A es una variable aleatoria pero B esta anidada en A

```{r, eval = FALSE}
aov(Y ~ B + Error(A/B), data=d)
```


* B y X interactuan dentro de niveles aleatorios de A

```{r, eval = FALSE}
aov(Y ~ (B*X) + Error(A/(B*X)), data=d)
```

## Referencias

<!--chapter:end:06Guia7.Rmd-->

# Tipos de errores cuadrados {#TipoError}

Para este capitulo necesitas tener instalado el paquete *car*, también ayuda tener el paquete *broom*. Esta clase del curso puede también ser seguida en este [link](http://www.derek-corcoran-barrios.com/AyudantiaStatsPres/Clase8/Clase8.html)


```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
suppressMessages(suppressWarnings(library(tidyverse, quietly = TRUE)))
options("kableExtra.html.bsTable" = T)
library(kableExtra)
```

## Objetivos del práctico

* Entender la diferencia entre los distintos tipos de sumas de cuadrado
* Saber los pro y los contras de cada uno
* Entender cuando usar cada tipo de sumas de cuadrados

## Cuadrados medios esperados

### Cuadrados medios de tipo I

Este es el tipo de errores cuadrados por defecto en R, es el ideal para usarlo en modelos anidados

#### Ventajas de error tipo I

La suma de los cuadrados

#### Desventajas del error tipo I

El orden importa, no es igual poner `y ~ A*B` que `y ~ B*A`:


```{r, echo = TRUE}
anova(lm(mpg ~ am*cyl, data = mtcars))
anova(lm(mpg ~ cyl*am, data = mtcars))
```


Esto es debido a que los errores se van calculando secuencialmente, entonces en el primer caso vemos cual es la variabilidad explicada por am, seguido de cuanto es explicado por cyl dado am y finalmente cuanto es explicado por la interacción dado am y cyl. Esto hace que se preste muy bien para un diseño anidado


#### Cuando usarlo

Diseños anidados

#### Cuando no usarlo

Para diseños factoriales



### Cuadrados medios de tipo II

Este es el tipo de errores cuadrados por defecto en R,


### Paquete EMSaov

El paquete de `R` *EMSaov* [@RJ-2017-011] permite calcular de forma presisa y dependiente del diseño los cuadrados medios esperados, lo cual entre otras cosas depende de si las variables son fijas o aleatoreas, recordemos del modluo pasado que:

* **Variables fijas:** Se espera que tengan una influencia predecible y sistemática en sobre lo que queremos explicar. Además usan todos los niveles de un factor (Ejemplo genero)
    
* **Variables aleatorias:** Se espera que su influencia sea impredecible e idiosincratica. Además no se usan todos los niveles de un factor (todos los individuos)


```{r, echo = TRUE}
A        = c("a", "a", "a", "a", "b", "b", "b", "b", "b", "b", "b", "b")
B        = c("x", "y", "x", "y", "x", "y", "x", "y", "x", "x", "x", "x")
C        = c("l", "l", "m", "m", "l", "l", "m", "m", "l", "l", "l", "l")
response = c( 14,  30,  15,  35,  50,  51,  30,  32,  51,  55,  53,  55)

summary(aov(response ~ A + B + C + A:B + A:C + B:C))


model = lm(response ~ A + B + C + A:B + A:C + B:C)

anova(model)              # Type I tests


library(car)

Anova(model, type="II")   # Type II tests

Anova(model, type="III")
```

<!--chapter:end:07Guia8.Rmd-->

`r if (knitr::is_html_output()) '
# Referencias {#Refs}
'`

<!--chapter:end:09-referencias.Rmd-->

